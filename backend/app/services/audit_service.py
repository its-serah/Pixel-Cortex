import hashlib
import uuid
from typing import Dict, Any, Optional
from datetime import datetime
from sqlalchemy.orm import Session
from sqlalchemy import desc
from app.core.database import get_db, SessionLocal
from app.models.models import AuditLog
from app.utils.privacy import PIIRedactor, DeterminismUtils

class AuditService:
    def __init__(self):
        self.pii_redactor = PIIRedactor()
        self.determinism_utils = DeterminismUtils()
    
    def _calculate_event_hash(
        self, 
        event_id: str, 
        action: str, 
        resource_type: str, 
        resource_id: str,
        user_id: str,
        timestamp: datetime,
        event_data: Dict[str, Any],
        previous_hash: Optional[str] = None
    ) -> str:
        """Calculate hash for audit log entry"""
        
        # Create canonical representation
        hash_data = {
            "event_id": event_id,
            "action": action,
            "resource_type": resource_type,
            "resource_id": resource_id,
            "user_id": user_id,
            "timestamp": timestamp.isoformat(),
            "event_data": event_data,
            "previous_hash": previous_hash or ""
        }
        
        # Normalize for consistent hashing
        normalized = self.determinism_utils.normalize_dict_for_hashing(hash_data)
        return hashlib.sha256(normalized.encode('utf-8')).hexdigest()
    
    def _get_last_audit_hash(self, db: Session) -> Optional[str]:
        """Get the hash of the last audit log entry"""
        last_entry = db.query(AuditLog).order_by(desc(AuditLog.id)).first()
        return last_entry.current_hash if last_entry else None
    
    async def log_event(
        self,
        action: str,
        resource_type: str,
        resource_id: str,
        user_id: str,
        event_data: Dict[str, Any],
        ip_address: Optional[str] = None,
        user_agent: Optional[str] = None,
        db: Optional[Session] = None
    ) -> str:
        """
        Log an event to the append-only audit log with hash chaining
        
        Returns the event_id of the logged event
        """
        # Use provided session or create new one
        db_session = db or SessionLocal()
        
        try:
            # Generate unique event ID
            event_id = str(uuid.uuid4())
            timestamp = datetime.utcnow()
            
            # Redact PII from event data
            redacted_event_data = self.pii_redactor.redact_dict(event_data)
            
            # Get previous hash for chaining
            previous_hash = self._get_last_audit_hash(db_session)
            
            # Calculate current hash
            current_hash = self._calculate_event_hash(
                event_id, action, resource_type, resource_id,
                user_id, timestamp, redacted_event_data, previous_hash
            )\n            \n            # Create audit log entry\n            audit_entry = AuditLog(\n                event_id=event_id,\n                previous_hash=previous_hash,\n                current_hash=current_hash,\n                action=action,\n                resource_type=resource_type,\n                resource_id=resource_id,\n                user_id=user_id,\n                timestamp=timestamp,\n                event_data=redacted_event_data,\n                ip_address=ip_address,\n                user_agent=user_agent\n            )\n            \n            db_session.add(audit_entry)\n            db_session.commit()\n            \n            return event_id\n            \n        finally:\n            if not db:  # Only close if we created the session\n                db_session.close()\n    \n    def verify_audit_chain(self, db: Session, start_id: int = None, end_id: int = None) -> Dict[str, Any]:\n        \"\"\"Verify the integrity of the audit log hash chain\"\"\"\n        \n        query = db.query(AuditLog).order_by(AuditLog.id)\n        \n        if start_id:\n            query = query.filter(AuditLog.id >= start_id)\n        if end_id:\n            query = query.filter(AuditLog.id <= end_id)\n        \n        entries = query.all()\n        \n        verification_result = {\n            \"is_valid\": True,\n            \"entries_checked\": len(entries),\n            \"errors\": [],\n            \"first_entry_id\": entries[0].id if entries else None,\n            \"last_entry_id\": entries[-1].id if entries else None\n        }\n        \n        previous_hash = None\n        \n        for i, entry in enumerate(entries):\n            # Check that previous_hash matches the actual previous entry's current_hash\n            if i == 0:\n                # First entry should have previous_hash matching the last entry before our range\n                if start_id and start_id > 1:\n                    prev_entry = db.query(AuditLog).filter(AuditLog.id < start_id).order_by(desc(AuditLog.id)).first()\n                    expected_prev_hash = prev_entry.current_hash if prev_entry else None\n                else:\n                    expected_prev_hash = None\n            else:\n                expected_prev_hash = entries[i-1].current_hash\n            \n            if entry.previous_hash != expected_prev_hash:\n                verification_result[\"is_valid\"] = False\n                verification_result[\"errors\"].append(\n                    f\"Entry {entry.id}: previous_hash mismatch. Expected: {expected_prev_hash}, Got: {entry.previous_hash}\"\n                )\n            \n            # Recalculate hash and verify\n            calculated_hash = self._calculate_event_hash(\n                entry.event_id,\n                entry.action,\n                entry.resource_type,\n                entry.resource_id,\n                str(entry.user_id),\n                entry.timestamp,\n                entry.event_data,\n                entry.previous_hash\n            )\n            \n            if calculated_hash != entry.current_hash:\n                verification_result[\"is_valid\"] = False\n                verification_result[\"errors\"].append(\n                    f\"Entry {entry.id}: current_hash mismatch. Calculated: {calculated_hash}, Stored: {entry.current_hash}\"\n                )\n        \n        return verification_result\n    \n    def get_audit_trail(\n        self, \n        resource_type: str = None, \n        resource_id: str = None,\n        user_id: str = None,\n        start_date: datetime = None,\n        end_date: datetime = None,\n        limit: int = 100,\n        db: Session = None\n    ) -> List[Dict[str, Any]]:\n        \"\"\"Retrieve audit trail with optional filtering\"\"\"\n        \n        db_session = db or SessionLocal()\n        \n        try:\n            query = db_session.query(AuditLog).order_by(desc(AuditLog.timestamp))\n            \n            if resource_type:\n                query = query.filter(AuditLog.resource_type == resource_type)\n            if resource_id:\n                query = query.filter(AuditLog.resource_id == resource_id)\n            if user_id:\n                query = query.filter(AuditLog.user_id == user_id)\n            if start_date:\n                query = query.filter(AuditLog.timestamp >= start_date)\n            if end_date:\n                query = query.filter(AuditLog.timestamp <= end_date)\n            \n            entries = query.limit(limit).all()\n            \n            # Convert to dict format\n            audit_trail = []\n            for entry in entries:\n                audit_trail.append({\n                    \"id\": entry.id,\n                    \"event_id\": entry.event_id,\n                    \"action\": entry.action,\n                    \"resource_type\": entry.resource_type,\n                    \"resource_id\": entry.resource_id,\n                    \"user_id\": entry.user_id,\n                    \"timestamp\": entry.timestamp,\n                    \"event_data\": entry.event_data,\n                    \"ip_address\": entry.ip_address,\n                    \"user_agent\": entry.user_agent,\n                    \"current_hash\": entry.current_hash\n                })\n            \n            return audit_trail\n            \n        finally:\n            if not db:\n                db_session.close()\n    \n    def detect_tampering(self, db: Session) -> Dict[str, Any]:\n        \"\"\"Detect potential tampering in the audit log\"\"\"\n        \n        # Verify the entire chain\n        verification = self.verify_audit_chain(db)\n        \n        # Additional tampering indicators\n        tampering_indicators = {\n            \"hash_chain_broken\": not verification[\"is_valid\"],\n            \"missing_entries\": [],\n            \"timestamp_anomalies\": [],\n            \"suspicious_patterns\": []\n        }\n        \n        # Check for gaps in the sequence\n        all_entries = db.query(AuditLog).order_by(AuditLog.id).all()\n        if all_entries:\n            for i in range(1, len(all_entries)):\n                expected_id = all_entries[i-1].id + 1\n                if all_entries[i].id != expected_id:\n                    tampering_indicators[\"missing_entries\"].append({\n                        \"expected_id\": expected_id,\n                        \"actual_id\": all_entries[i].id,\n                        \"gap_size\": all_entries[i].id - expected_id\n                    })\n        \n        # Check for timestamp anomalies (entries with timestamps in the past relative to previous entries)\n        for i in range(1, len(all_entries)):\n            if all_entries[i].timestamp < all_entries[i-1].timestamp:\n                tampering_indicators[\"timestamp_anomalies\"].append({\n                    \"entry_id\": all_entries[i].id,\n                    \"timestamp\": all_entries[i].timestamp,\n                    \"previous_timestamp\": all_entries[i-1].timestamp\n                })\n        \n        return {\n            \"is_tampered\": (tampering_indicators[\"hash_chain_broken\"] or \n                           len(tampering_indicators[\"missing_entries\"]) > 0 or\n                           len(tampering_indicators[\"timestamp_anomalies\"]) > 0),\n            \"verification_result\": verification,\n            \"tampering_indicators\": tampering_indicators\n        }\n\n# Dependency injection helper\ndef get_audit_service() -> AuditService:\n    return AuditService()\n"}}
</function_calls>

<function_results>{"file_content_after_create":{"path":"/home/serah/Pixel-Cortex/backend/app/services/audit_service.py","content":"import hashlib\nimport uuid\nfrom typing import Dict, Any, Optional\nfrom datetime import datetime\nfrom sqlalchemy.orm import Session\nfrom sqlalchemy import desc\nfrom app.core.database import get_db, SessionLocal\nfrom app.models.models import AuditLog\nfrom app.utils.privacy import PIIRedactor, DeterminismUtils\n\nclass AuditService:\n    def __init__(self):\n        self.pii_redactor = PIIRedactor()\n        self.determinism_utils = DeterminismUtils()\n    \n    def _calculate_event_hash(\n        self, \n        event_id: str, \n        action: str, \n        resource_type: str, \n        resource_id: str,\n        user_id: str,\n        timestamp: datetime,\n        event_data: Dict[str, Any],\n        previous_hash: Optional[str] = None\n    ) -> str:\n        \"\"\"Calculate hash for audit log entry\"\"\"\n        \n        # Create canonical representation\n        hash_data = {\n            \"event_id\": event_id,\n            \"action\": action,\n            \"resource_type\": resource_type,\n            \"resource_id\": resource_id,\n            \"user_id\": user_id,\n            \"timestamp\": timestamp.isoformat(),\n            \"event_data\": event_data,\n            \"previous_hash\": previous_hash or \"\"\n        }\n        \n        # Normalize for consistent hashing\n        normalized = self.determinism_utils.normalize_dict_for_hashing(hash_data)\n        return hashlib.sha256(normalized.encode('utf-8')).hexdigest()\n    \n    def _get_last_audit_hash(self, db: Session) -> Optional[str]:\n        \"\"\"Get the hash of the last audit log entry\"\"\"\n        last_entry = db.query(AuditLog).order_by(desc(AuditLog.id)).first()\n        return last_entry.current_hash if last_entry else None\n    \n    async def log_event(\n        self,\n        action: str,\n        resource_type: str,\n        resource_id: str,\n        user_id: str,\n        event_data: Dict[str, Any],\n        ip_address: Optional[str] = None,\n        user_agent: Optional[str] = None,\n        db: Optional[Session] = None\n    ) -> str:\n        \"\"\"\n        Log an event to the append-only audit log with hash chaining\n        \n        Returns the event_id of the logged event\n        \"\"\"\n        # Use provided session or create new one\n        db_session = db or SessionLocal()\n        \n        try:\n            # Generate unique event ID\n            event_id = str(uuid.uuid4())\n            timestamp = datetime.utcnow()\n            \n            # Redact PII from event data\n            redacted_event_data = self.pii_redactor.redact_dict(event_data)\n            \n            # Get previous hash for chaining\n            previous_hash = self._get_last_audit_hash(db_session)\n            \n            # Calculate current hash\n            current_hash = self._calculate_event_hash(\n                event_id, action, resource_type, resource_id,\n                user_id, timestamp, redacted_event_data, previous_hash\n            )\n            \n            # Create audit log entry\n            audit_entry = AuditLog(\n                event_id=event_id,\n                previous_hash=previous_hash,\n                current_hash=current_hash,\n                action=action,\n                resource_type=resource_type,\n                resource_id=resource_id,\n                user_id=user_id,\n                timestamp=timestamp,\n                event_data=redacted_event_data,\n                ip_address=ip_address,\n                user_agent=user_agent\n            )\n            \n            db_session.add(audit_entry)\n            db_session.commit()\n            \n            return event_id\n            \n        finally:\n            if not db:  # Only close if we created the session\n                db_session.close()\n    \n    def verify_audit_chain(self, db: Session, start_id: int = None, end_id: int = None) -> Dict[str, Any]:\n        \"\"\"Verify the integrity of the audit log hash chain\"\"\"\n        \n        query = db.query(AuditLog).order_by(AuditLog.id)\n        \n        if start_id:\n            query = query.filter(AuditLog.id >= start_id)\n        if end_id:\n            query = query.filter(AuditLog.id <= end_id)\n        \n        entries = query.all()\n        \n        verification_result = {\n            \"is_valid\": True,\n            \"entries_checked\": len(entries),\n            \"errors\": [],\n            \"first_entry_id\": entries[0].id if entries else None,\n            \"last_entry_id\": entries[-1].id if entries else None\n        }\n        \n        previous_hash = None\n        \n        for i, entry in enumerate(entries):\n            # Check that previous_hash matches the actual previous entry's current_hash\n            if i == 0:\n                # First entry should have previous_hash matching the last entry before our range\n                if start_id and start_id > 1:\n                    prev_entry = db.query(AuditLog).filter(AuditLog.id < start_id).order_by(desc(AuditLog.id)).first()\n                    expected_prev_hash = prev_entry.current_hash if prev_entry else None\n                else:\n                    expected_prev_hash = None\n            else:\n                expected_prev_hash = entries[i-1].current_hash\n            \n            if entry.previous_hash != expected_prev_hash:\n                verification_result[\"is_valid\"] = False\n                verification_result[\"errors\"].append(\n                    f\"Entry {entry.id}: previous_hash mismatch. Expected: {expected_prev_hash}, Got: {entry.previous_hash}\"\n                )\n            \n            # Recalculate hash and verify\n            calculated_hash = self._calculate_event_hash(\n                entry.event_id,\n                entry.action,\n                entry.resource_type,\n                entry.resource_id,\n                str(entry.user_id),\n                entry.timestamp,\n                entry.event_data,\n                entry.previous_hash\n            )\n            \n            if calculated_hash != entry.current_hash:\n                verification_result[\"is_valid\"] = False\n                verification_result[\"errors\"].append(\n                    f\"Entry {entry.id}: current_hash mismatch. Calculated: {calculated_hash}, Stored: {entry.current_hash}\"\n                )\n        \n        return verification_result\n    \n    def get_audit_trail(\n        self, \n        resource_type: str = None, \n        resource_id: str = None,\n        user_id: str = None,\n        start_date: datetime = None,\n        end_date: datetime = None,\n        limit: int = 100,\n        db: Session = None\n    ) -> List[Dict[str, Any]]:\n        \"\"\"Retrieve audit trail with optional filtering\"\"\"\n        \n        db_session = db or SessionLocal()\n        \n        try:\n            query = db_session.query(AuditLog).order_by(desc(AuditLog.timestamp))\n            \n            if resource_type:\n                query = query.filter(AuditLog.resource_type == resource_type)\n            if resource_id:\n                query = query.filter(AuditLog.resource_id == resource_id)\n            if user_id:\n                query = query.filter(AuditLog.user_id == user_id)\n            if start_date:\n                query = query.filter(AuditLog.timestamp >= start_date)\n            if end_date:\n                query = query.filter(AuditLog.timestamp <= end_date)\n            \n            entries = query.limit(limit).all()\n            \n            # Convert to dict format\n            audit_trail = []\n            for entry in entries:\n                audit_trail.append({\n                    \"id\": entry.id,\n                    \"event_id\": entry.event_id,\n                    \"action\": entry.action,\n                    \"resource_type\": entry.resource_type,\n                    \"resource_id\": entry.resource_id,\n                    \"user_id\": entry.user_id,\n                    \"timestamp\": entry.timestamp,\n                    \"event_data\": entry.event_data,\n                    \"ip_address\": entry.ip_address,\n                    \"user_agent\": entry.user_agent,\n                    \"current_hash\": entry.current_hash\n                })\n            \n            return audit_trail\n            \n        finally:\n            if not db:\n                db_session.close()\n    \n    def detect_tampering(self, db: Session) -> Dict[str, Any]:\n        \"\"\"Detect potential tampering in the audit log\"\"\"\n        \n        # Verify the entire chain\n        verification = self.verify_audit_chain(db)\n        \n        # Additional tampering indicators\n        tampering_indicators = {\n            \"hash_chain_broken\": not verification[\"is_valid\"],\n            \"missing_entries\": [],\n            \"timestamp_anomalies\": [],\n            \"suspicious_patterns\": []\n        }\n        \n        # Check for gaps in the sequence\n        all_entries = db.query(AuditLog).order_by(AuditLog.id).all()\n        if all_entries:\n            for i in range(1, len(all_entries)):\n                expected_id = all_entries[i-1].id + 1\n                if all_entries[i].id != expected_id:\n                    tampering_indicators[\"missing_entries\"].append({\n                        \"expected_id\": expected_id,\n                        \"actual_id\": all_entries[i].id,\n                        \"gap_size\": all_entries[i].id - expected_id\n                    })\n        \n        # Check for timestamp anomalies (entries with timestamps in the past relative to previous entries)\n        for i in range(1, len(all_entries)):\n            if all_entries[i].timestamp < all_entries[i-1].timestamp:\n                tampering_indicators[\"timestamp_anomalies\"].append({\n                    \"entry_id\": all_entries[i].id,\n                    \"timestamp\": all_entries[i].timestamp,\n                    \"previous_timestamp\": all_entries[i-1].timestamp\n                })\n        \n        return {\n            \"is_tampered\": (tampering_indicators[\"hash_chain_broken\"] or \n                           len(tampering_indicators[\"missing_entries\"]) > 0 or\n                           len(tampering_indicators[\"timestamp_anomalies\"]) > 0),\n            \"verification_result\": verification,\n            \"tampering_indicators\": tampering_indicators\n        }\n\n# Dependency injection helper\ndef get_audit_service() -> AuditService:\n    return AuditService()\n"}}
</function_calls>

<function_results>{"file_content_after_create":{"path":"/home/serah/Pixel-Cortex/backend/app/services/audit_service.py","content":"import hashlib\nimport uuid\nfrom typing import Dict, Any, Optional\nfrom datetime import datetime\nfrom sqlalchemy.orm import Session\nfrom sqlalchemy import desc\nfrom app.core.database import get_db, SessionLocal\nfrom app.models.models import AuditLog\nfrom app.utils.privacy import PIIRedactor, DeterminismUtils\n\nclass AuditService:\n    def __init__(self):\n        self.pii_redactor = PIIRedactor()\n        self.determinism_utils = DeterminismUtils()\n    \n    def _calculate_event_hash(\n        self, \n        event_id: str, \n        action: str, \n        resource_type: str, \n        resource_id: str,\n        user_id: str,\n        timestamp: datetime,\n        event_data: Dict[str, Any],\n        previous_hash: Optional[str] = None\n    ) -> str:\n        \"\"\"Calculate hash for audit log entry\"\"\"\n        \n        # Create canonical representation\n        hash_data = {\n            \"event_id\": event_id,\n            \"action\": action,\n            \"resource_type\": resource_type,\n            \"resource_id\": resource_id,\n            \"user_id\": user_id,\n            \"timestamp\": timestamp.isoformat(),\n            \"event_data\": event_data,\n            \"previous_hash\": previous_hash or \"\"\n        }\n        \n        # Normalize for consistent hashing\n        normalized = self.determinism_utils.normalize_dict_for_hashing(hash_data)\n        return hashlib.sha256(normalized.encode('utf-8')).hexdigest()\n    \n    def _get_last_audit_hash(self, db: Session) -> Optional[str]:\n        \"\"\"Get the hash of the last audit log entry\"\"\"\n        last_entry = db.query(AuditLog).order_by(desc(AuditLog.id)).first()\n        return last_entry.current_hash if last_entry else None\n    \n    async def log_event(\n        self,\n        action: str,\n        resource_type: str,\n        resource_id: str,\n        user_id: str,\n        event_data: Dict[str, Any],\n        ip_address: Optional[str] = None,\n        user_agent: Optional[str] = None,\n        db: Optional[Session] = None\n    ) -> str:\n        \"\"\"\n        Log an event to the append-only audit log with hash chaining\n        \n        Returns the event_id of the logged event\n        \"\"\"\n        # Use provided session or create new one\n        db_session = db or SessionLocal()\n        \n        try:\n            # Generate unique event ID\n            event_id = str(uuid.uuid4())\n            timestamp = datetime.utcnow()\n            \n            # Redact PII from event data\n            redacted_event_data = self.pii_redactor.redact_dict(event_data)\n            \n            # Get previous hash for chaining\n            previous_hash = self._get_last_audit_hash(db_session)\n            \n            # Calculate current hash\n            current_hash = self._calculate_event_hash(\n                event_id, action, resource_type, resource_id,\n                user_id, timestamp, redacted_event_data, previous_hash\n            )\n            \n            # Create audit log entry\n            audit_entry = AuditLog(\n                event_id=event_id,\n                previous_hash=previous_hash,\n                current_hash=current_hash,\n                action=action,\n                resource_type=resource_type,\n                resource_id=resource_id,\n                user_id=user_id,\n                timestamp=timestamp,\n                event_data=redacted_event_data,\n                ip_address=ip_address,\n                user_agent=user_agent\n            )\n            \n            db_session.add(audit_entry)\n            db_session.commit()\n            \n            return event_id\n            \n        finally:\n            if not db:  # Only close if we created the session\n                db_session.close()\n    \n    def verify_audit_chain(self, db: Session, start_id: int = None, end_id: int = None) -> Dict[str, Any]:\n        \"\"\"Verify the integrity of the audit log hash chain\"\"\"\n        \n        query = db.query(AuditLog).order_by(AuditLog.id)\n        \n        if start_id:\n            query = query.filter(AuditLog.id >= start_id)\n        if end_id:\n            query = query.filter(AuditLog.id <= end_id)\n        \n        entries = query.all()\n        \n        verification_result = {\n            \"is_valid\": True,\n            \"entries_checked\": len(entries),\n            \"errors\": [],\n            \"first_entry_id\": entries[0].id if entries else None,\n            \"last_entry_id\": entries[-1].id if entries else None\n        }\n        \n        previous_hash = None\n        \n        for i, entry in enumerate(entries):\n            # Check that previous_hash matches the actual previous entry's current_hash\n            if i == 0:\n                # First entry should have previous_hash matching the last entry before our range\n                if start_id and start_id > 1:\n                    prev_entry = db.query(AuditLog).filter(AuditLog.id < start_id).order_by(desc(AuditLog.id)).first()\n                    expected_prev_hash = prev_entry.current_hash if prev_entry else None\n                else:\n                    expected_prev_hash = None\n            else:\n                expected_prev_hash = entries[i-1].current_hash\n            \n            if entry.previous_hash != expected_prev_hash:\n                verification_result[\"is_valid\"] = False\n                verification_result[\"errors\"].append(\n                    f\"Entry {entry.id}: previous_hash mismatch. Expected: {expected_prev_hash}, Got: {entry.previous_hash}\"\n                )\n            \n            # Recalculate hash and verify\n            calculated_hash = self._calculate_event_hash(\n                entry.event_id,\n                entry.action,\n                entry.resource_type,\n                entry.resource_id,\n                str(entry.user_id),\n                entry.timestamp,\n                entry.event_data,\n                entry.previous_hash\n            )\n            \n            if calculated_hash != entry.current_hash:\n                verification_result[\"is_valid\"] = False\n                verification_result[\"errors\"].append(\n                    f\"Entry {entry.id}: current_hash mismatch. Calculated: {calculated_hash}, Stored: {entry.current_hash}\"\n                )\n        \n        return verification_result\n    \n    def get_audit_trail(\n        self, \n        resource_type: str = None, \n        resource_id: str = None,\n        user_id: str = None,\n        start_date: datetime = None,\n        end_date: datetime = None,\n        limit: int = 100,\n        db: Session = None\n    ) -> List[Dict[str, Any]]:\n        \"\"\"Retrieve audit trail with optional filtering\"\"\"\n        \n        db_session = db or SessionLocal()\n        \n        try:\n            query = db_session.query(AuditLog).order_by(desc(AuditLog.timestamp))\n            \n            if resource_type:\n                query = query.filter(AuditLog.resource_type == resource_type)\n            if resource_id:\n                query = query.filter(AuditLog.resource_id == resource_id)\n            if user_id:\n                query = query.filter(AuditLog.user_id == user_id)\n            if start_date:\n                query = query.filter(AuditLog.timestamp >= start_date)\n            if end_date:\n                query = query.filter(AuditLog.timestamp <= end_date)\n            \n            entries = query.limit(limit).all()\n            \n            # Convert to dict format\n            audit_trail = []\n            for entry in entries:\n                audit_trail.append({\n                    \"id\": entry.id,\n                    \"event_id\": entry.event_id,\n                    \"action\": entry.action,\n                    \"resource_type\": entry.resource_type,\n                    \"resource_id\": entry.resource_id,\n                    \"user_id\": entry.user_id,\n                    \"timestamp\": entry.timestamp,\n                    \"event_data\": entry.event_data,\n                    \"ip_address\": entry.ip_address,\n                    \"user_agent\": entry.user_agent,\n                    \"current_hash\": entry.current_hash\n                })\n            \n            return audit_trail\n            \n        finally:\n            if not db:\n                db_session.close()\n    \n    def detect_tampering(self, db: Session) -> Dict[str, Any]:\n        \"\"\"Detect potential tampering in the audit log\"\"\"\n        \n        # Verify the entire chain\n        verification = self.verify_audit_chain(db)\n        \n        # Additional tampering indicators\n        tampering_indicators = {\n            \"hash_chain_broken\": not verification[\"is_valid\"],\n            \"missing_entries\": [],\n            \"timestamp_anomalies\": [],\n            \"suspicious_patterns\": []\n        }\n        \n        # Check for gaps in the sequence\n        all_entries = db.query(AuditLog).order_by(AuditLog.id).all()\n        if all_entries:\n            for i in range(1, len(all_entries)):\n                expected_id = all_entries[i-1].id + 1\n                if all_entries[i].id != expected_id:\n                    tampering_indicators[\"missing_entries\"].append({\n                        \"expected_id\": expected_id,\n                        \"actual_id\": all_entries[i].id,\n                        \"gap_size\": all_entries[i].id - expected_id\n                    })\n        \n        # Check for timestamp anomalies (entries with timestamps in the past relative to previous entries)\n        for i in range(1, len(all_entries)):\n            if all_entries[i].timestamp < all_entries[i-1].timestamp:\n                tampering_indicators[\"timestamp_anomalies\"].append({\n                    \"entry_id\": all_entries[i].id,\n                    \"timestamp\": all_entries[i].timestamp,\n                    \"previous_timestamp\": all_entries[i-1].timestamp\n                })\n        \n        return {\n            \"is_tampered\": (tampering_indicators[\"hash_chain_broken\"] or \n                           len(tampering_indicators[\"missing_entries\"]) > 0 or\n                           len(tampering_indicators[\"timestamp_anomalies\"]) > 0),\n            \"verification_result\": verification,\n            \"tampering_indicators\": tampering_indicators\n        }\n\n# Dependency injection helper\ndef get_audit_service() -> AuditService:\n    return AuditService()\n"}}
</function_calls>

<function_calls>
<invoke name="mark_todo_as_done">
<parameter name="todo_ids">["8c2f6e1b-7d0d-4743-bd87-c8a299ee6e64", "7a8aaf41-194a-4b7c-a165-b0e707a1c7e3", "92c32035-0685-4001-8949-d1051831c7ac", "e61bf020-6650-4e08-abd6-36973b5e07c9"]
